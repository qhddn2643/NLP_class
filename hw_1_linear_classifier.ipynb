{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2e9df26-2828-4f4b-8916-211b492db181",
      "metadata": {
        "id": "f2e9df26-2828-4f4b-8916-211b492db181"
      },
      "source": [
        "# Text classification with sklearn and linear models\n",
        "\n",
        "Text classification is one of the most popular applications of NLP.\n",
        "Your email checks if the message looks like spam or not (binary classification).\n",
        "Your smart speaker needs to understand what action it should do when you say \"what's the weather like today?\".\n",
        "This is a classification task over a large number of classes `get_time, get_directions, get_weather, ...` (multiclass classification).\n",
        "Other popular classification tasks include news topic prediction, clickbait detection, hate speech detection, and sentiment analysis.\n",
        "\n",
        "*Sentiment analysis* is a task where (in the simplest form) given a text you need to predict if the text is positive (\"my new laptop is amazing\") or negative (\"the company XYZ steals our personal data\"). The definitions of \"positive\" and \"negative\" generally depend on the domain of your task. For example \"long-lasting smell\" may carry positive sentiment in the context of perfume but might be negative in the context of a cleaning solution. Sentiment analysis systems could be used by the companies who want to understand how positive was the social media reaction to their latest announcement or in the user feedback forms to address the negative feedback quickly.\n",
        "\n",
        "In this homework, we will be predicting the sentiment of movie reviews using IMDB dataset. First, let's use [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download it for us."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets scikit-learn matplotlib"
      ],
      "metadata": {
        "id": "T72mnxIMdztc",
        "outputId": "89f50a38-a1fe-4389-af79-5b2f7d78dcb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T72mnxIMdztc",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.10)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8b579c32-1a2e-46c3-bee3-8f41ee35cda1",
      "metadata": {
        "id": "8b579c32-1a2e-46c3-bee3-8f41ee35cda1",
        "outputId": "ac2e0f9c-3467-403e-d3e1-9215107c503f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d9a41ee0086a4d60a4eccdf02562e35c",
            "469d2bbedf3d4f8cbfc9b0f1ed4237f2",
            "c8989b49998d437f845da27a90a4f7f9",
            "304fb578e5bb4a338457730410c1d1a6",
            "e3c7aa497f234e37b1acf1e5b4b062f9",
            "84b9c1f76f4144be846938c00fa0281a",
            "f8e53d2ec5254279b828ef1447a0f20a",
            "df8b9ba71aaa4294b35454b7510c0ec7",
            "429e74a1955046b6be3fe063e170ce26",
            "39305c3c7b3b473e94eea5187dba2337",
            "5cd4b8c3c125411392bb627be428f191"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9a41ee0086a4d60a4eccdf02562e35c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import datasets\n",
        "imdb = datasets.load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d28c68d-924a-472e-bc4e-ba83a302a27e",
      "metadata": {
        "id": "6d28c68d-924a-472e-bc4e-ba83a302a27e"
      },
      "source": [
        "ðŸ¤— Datasets is a popular [library](https://huggingface.co/docs/datasets) and a [repository](https://huggingface.co/datasets) of datasets.\n",
        "It can be used to download pre-existing datasets, pre-process them, and could be applied to your own datasets too.\n",
        "In this homework we will mostly just use it to download the dataset and look at some of its statistics, but in the future, you will learn more about it.\n",
        "\n",
        "Let's look at the dataset we have just downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "947adfd2-4467-4954-b9cd-b33edcbfe7cf",
      "metadata": {
        "id": "947adfd2-4467-4954-b9cd-b33edcbfe7cf",
        "outputId": "d2337648-6a5c-44ba-b302-6e3a02e1d4f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb1dee2-27ba-4188-9dde-380b3761d55d",
      "metadata": {
        "id": "5fb1dee2-27ba-4188-9dde-380b3761d55d"
      },
      "source": [
        "We see that `imdb` has type `DatasetDict` and it consists of three parts (commonly called \"splits\"): `train`, `test`, and `unsupervised`. All of these have the type `Dataset`. The subset `train` has 25000 examples and we will use it to train our model, `test` also contains 25000 examples (which is an uncommonly large size of test size, usually test is significantly smaller than train). Both of these splits have fields `text` and `label` containing the movie review text and a label if the review is positive or not.\n",
        "\n",
        "`unsupervised` set does not have labels (all of them are -1 irregardless of their sentiment). More advanced ML methods can utilize this to improve model accuracy, but we will not use it in this homework.\n",
        "\n",
        "# Coding Task 1\n",
        "Let's look at a couple of examples from the train split. You can index the `Dataset` object just like usual python arrays providing the index in square brackets, for example  `train_set[0]` with return you the first element of the dataset. Try looking at the first and the last elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1ccb90ef-fd32-41e6-b091-28ae4011066a",
      "metadata": {
        "id": "1ccb90ef-fd32-41e6-b091-28ae4011066a"
      },
      "outputs": [],
      "source": [
        "train_set = imdb[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "87c8980c-1dcc-4c82-8eeb-3b0ebfe77458",
      "metadata": {
        "id": "87c8980c-1dcc-4c82-8eeb-3b0ebfe77458",
        "outputId": "f196eeb9-00b2-4c76-cc1e-da535fc6fd45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Get the first element of the train_set\n",
        "# YOUR CODE HERE\n",
        "train_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4ef6cfd1-96ba-4400-9d6e-0a6d4da69b97",
      "metadata": {
        "id": "4ef6cfd1-96ba-4400-9d6e-0a6d4da69b97",
        "outputId": "712f0794-c9df-4b45-e4de-713abbf7f10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Get the last element of the train_set\n",
        "# YOUR CODE HERE\n",
        "train_set[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12b9911-adbb-454d-95ca-31702d091320",
      "metadata": {
        "id": "e12b9911-adbb-454d-95ca-31702d091320"
      },
      "source": [
        "## Dataset statistics\n",
        "\n",
        "A good first thing to do when you see a new dataset is to look at its statistics. For example at the distributions of classes, and lengths of the texts.\n",
        "\n",
        "We can use python [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp) and function `sum` to quickly get the answer to our first question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "004e7bd0-acfb-4a4e-b805-48d983988f9c",
      "metadata": {
        "id": "004e7bd0-acfb-4a4e-b805-48d983988f9c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "774fbc62-a2ce-4998-82a0-70d9cee3bdd8",
      "metadata": {
        "id": "774fbc62-a2ce-4998-82a0-70d9cee3bdd8",
        "outputId": "9e0e866a-4934-4897-c495-77f8081e0847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N positive:  12500\n",
            "N negative:  12500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_positive_examples = sum(label == 1 for label in train_set[\"label\"])\n",
        "n_negative_examples = sum(label == 0 for label in train_set[\"label\"])\n",
        "\n",
        "plt.bar(x=[\"positive\", \"negative\"], height=[n_positive_examples, n_negative_examples])\n",
        "print(\"N positive: \", n_positive_examples)\n",
        "print(\"N negative: \", n_negative_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb12efe7-f515-4392-bf23-4dfaf58b520f",
      "metadata": {
        "id": "fb12efe7-f515-4392-bf23-4dfaf58b520f"
      },
      "source": [
        "Looks like the training set is perfectly balanced. What about the test set?\n",
        "\n",
        "# Coding Task 2\n",
        "\n",
        "Compute the number of positive and negative labels in the test set. Print the numbers and make a matplotlib barplot in the same way we did above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a3097b3a-381b-4df4-a906-9061ea074707",
      "metadata": {
        "id": "a3097b3a-381b-4df4-a906-9061ea074707",
        "outputId": "c648ab43-e590-4204-c48f-b7a43804b3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N positive:  12500\n",
            "N negative:  12500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "test_set = imdb[\"test\"]\n",
        "\n",
        "# YOUR CODE HERE\n",
        "n_positive_examples = sum(label == 1 for label in test_set[\"label\"])\n",
        "n_negative_examples = sum(label == 0 for label in test_set[\"label\"])\n",
        "\n",
        "plt.bar(x=[\"positive\", \"negative\"], height=[n_positive_examples, n_negative_examples])\n",
        "print(\"N positive: \", n_positive_examples)\n",
        "print(\"N negative: \", n_negative_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ad3000-ac2c-47f6-827e-b16b44de47b6",
      "metadata": {
        "id": "68ad3000-ac2c-47f6-827e-b16b44de47b6"
      },
      "source": [
        "Now let's plot the distributions of the number of words in the dataset. For now, we will define \"word\" as a contiguous sequence of characters that does have a space symbol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "666657fd-8e00-4fac-82f3-db26d7c96292",
      "metadata": {
        "id": "666657fd-8e00-4fac-82f3-db26d7c96292",
        "outputId": "00b09077-b5e4-4eca-f67c-2bef49320f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_words_train = [len(text.split(\" \")) for text in train_set[\"text\"]]\n",
        "n_words_test = [len(text.split(\" \")) for text in test_set[\"text\"]]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(n_words_train, bins=30, label=\"train\")\n",
        "plt.hist(n_words_test, bins=30, label=\"test\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d003ed-daea-45c3-8692-aed1289f0c2b",
      "metadata": {
        "id": "92d003ed-daea-45c3-8692-aed1289f0c2b"
      },
      "source": [
        "Some of these texts are quite long. Fortunately, this is not a problem for the methods we are going to use today."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8db9fb-d191-406c-ab54-4e3e1d3de86c",
      "metadata": {
        "id": "ee8db9fb-d191-406c-ab54-4e3e1d3de86c"
      },
      "source": [
        "## What metric to use\n",
        "\n",
        "Now, after knowing something about the distribution of labels in the dataset, we can think about the metric we will use to compare our models.\n",
        "Because this is a binary classification task and everything is perfectly balanced, we can just use accuracy.\n",
        "\n",
        "# Inline question\n",
        "Answer the following questions\n",
        "\n",
        "\n",
        "**Q1:** What is the accuracy of the worst possible predictor on a balanced test set (binary classification)?\n",
        "\n",
        "**A:** 0%\n",
        "\n",
        "\n",
        "**Q2:** Imagine you have a predictor *A* that has 0% accuracy on your balanced binary classification task and another predictor *B* that has 50% accuracy on the same test set. Which model is actually worse? Can you improve any of these predictors with some simple post-processing of the results (the binary prediction)?\n",
        "\n",
        "**A:** Predictor A is worse than B. We can add more data to improve the binary prediction.\n",
        "\n",
        "\n",
        "**Q3:** Should the accuracy 99% be considered \"good\" for any binary classification dataset?\n",
        "\n",
        "**A:** Yes\n",
        "\n",
        "\n",
        "**Q4:** Imagine that you have a binary classification dataset that has 99.9% of one class and 0.1% of the other. What is the best possible accuracy for a predictor that completely ignores the text?\n",
        "\n",
        "**A:** 99.9% is best accuracy\n",
        "\n",
        "\n",
        "**Q5:** Is it a good idea to use accuracy as the main metric in the example above? Are there any other metrics that would work better in this situation?\n",
        "\n",
        "**A:** No, I think accuracy metric is not a good idea for imbalanced class problems. Precision and recall metrics are good for imbalanced class problems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714e9508-820e-449b-8a42-499ee9a742c5",
      "metadata": {
        "id": "714e9508-820e-449b-8a42-499ee9a742c5"
      },
      "source": [
        "## Text vectorization\n",
        "\n",
        "In the class, we have talked about possibly the simplest way to represent text to a computer: bag-of-words (BoW) approach. BoW assumes that the order of the words in the text does not matter. Sounds ridiculous? We will see it in action soon. Now, let's look into how it works.\n",
        "\n",
        "Scikit-learn (`sklearn`) is a popular framework for *Classical ML* and it includes many machine learning models including nearest-neighbors, trees, SVMs, and linear models.\n",
        "Also, it includes different pre-processing techniques. We will explore text vectorizers, namely `CountVectorizer` and `TfidfVectorizer`.\n",
        "\n",
        "Both of these vectorizers describe every text with a fixed-sized vector, where every vector position has a word associated with it.\n",
        "The difference between them is what numbers we set to these vector positions.\n",
        "\n",
        "`CountVectorizer` is the more simple one, because for it the number is just how many times the word appears in the text. For example, if your text is \"can a canner can a can\", it could be described with a vector [3, 2, 1] where 3 is the count of the word \"can\", 2 -- \"a\", and 1 -- \"canner\". In order for the vectors to be meaningful, the vectorizer needs to have a defined vocabulary of words it accounts for and the defined order of the words in the vocabulary so that the index 0 would always correspond to a word \"can\" in any text.\n",
        "\n",
        "Let's create a `CountVectorizer` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "feb4dde5-ace4-4701-b01f-51bf5521ed7c",
      "metadata": {
        "id": "feb4dde5-ace4-4701-b01f-51bf5521ed7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a2bb7a-01ed-450e-f056-e8f733afb6e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2db3aca-c300-4cf9-b35e-c13c14af5a2f",
      "metadata": {
        "id": "b2db3aca-c300-4cf9-b35e-c13c14af5a2f"
      },
      "source": [
        "It is not very useful right now. If you will try to use it to vectorize text (`.tranform` method),\n",
        "it will return you `NotFittedError: Vocabulary not fitted or provided`, because we have not defined the vocabulary for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e5e1cf8e-80a6-4e44-a980-23467e735b5b",
      "metadata": {
        "id": "e5e1cf8e-80a6-4e44-a980-23467e735b5b"
      },
      "outputs": [],
      "source": [
        "# you can uncomment this like and check that it fails if count_vectorizer is not fitted\n",
        "# count_vectorizer.transform([\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee6a9f1-80b9-40b5-bb8d-14d8cdf79064",
      "metadata": {
        "id": "7ee6a9f1-80b9-40b5-bb8d-14d8cdf79064"
      },
      "source": [
        "We can provide this vocabulary directly, but a more convenient way to work with sklearn vectorizers is to make them infer the vocabulary on a set of texts using `.fit` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "54787769-1cd9-4cdb-9b89-5c16cbd14909",
      "metadata": {
        "id": "54787769-1cd9-4cdb-9b89-5c16cbd14909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af566cf-829c-4515-a3fd-3413b59bcc33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'another': 0, 'is': 1, 'small': 2, 'text': 3, 'this': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "toy_texts = [\"this is a small text\", \"this is another small text\"]\n",
        "\n",
        "count_vectorizer = count_vectorizer.fit(toy_texts)\n",
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41f62b2f-4dfa-4f0f-8530-e13ec6b0a96c",
      "metadata": {
        "id": "41f62b2f-4dfa-4f0f-8530-e13ec6b0a96c"
      },
      "source": [
        "Now, we can vectorize a text like this\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ca81a041-32af-41cc-a5cb-e8129b1618d2",
      "metadata": {
        "id": "ca81a041-32af-41cc-a5cb-e8129b1618d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e12d82-b521-45b4-deb6-7e21f6694e0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "count_vectorizer.transform([\"text\"]).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "143019ca-6ce7-4a92-aede-13bafa7ce18d",
      "metadata": {
        "id": "143019ca-6ce7-4a92-aede-13bafa7ce18d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92560f7a-b855-4806-86c8-8815c5a934f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, 2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "count_vectorizer.transform([\"text text\"]).todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33ae7598-c3a6-4b1c-bf32-14392cde90a8",
      "metadata": {
        "id": "33ae7598-c3a6-4b1c-bf32-14392cde90a8"
      },
      "source": [
        "As you can see, the text \"text\" has 0s everywhere, except position 3, which corresponds to the number of times the word \"text\" appears (see the vocabulary one cell above).\n",
        "\n",
        "**Note:** `.todense` here transforms a sparse matrix that `.transform` returns into a dense matrix, you can learn more about [sparce maticies](https://en.wikipedia.org/wiki/Sparse_matrix), but it is not necessary for the purpose of this class.\n",
        "\n",
        "# Coding Task 3\n",
        "\n",
        "What if we vectorize text that has words outside vocabulary (out-of-vocabulary, OOV)? What if it only consists of them? Try vectorizing such texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b763c8a4-9a70-4410-9405-80edec6fdaff",
      "metadata": {
        "id": "b763c8a4-9a70-4410-9405-80edec6fdaff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a2a39a-b20e-4390-cee0-5b21330c780d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# vectorizing a text with a OOV word\n",
        "# YOUR CODE HERE\n",
        "count_vectorizer.transform([\"this is a Python code\"]).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "170c2697-c5e9-4044-b1c0-dd8254a7e53a",
      "metadata": {
        "id": "170c2697-c5e9-4044-b1c0-dd8254a7e53a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787d1ed6-30f5-4d27-ecf5-98c0d1c50829"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# vectorizing a text that only has OOV words\n",
        "# YOUR CODE HERE\n",
        "count_vectorizer.transform([\"I am teaching NLP in Python\"]).todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dce9c46-202b-431c-8a5b-6d26a0cfe65a",
      "metadata": {
        "id": "4dce9c46-202b-431c-8a5b-6d26a0cfe65a"
      },
      "source": [
        "Now, let's try `TfidfVectorizer`. It has pretty much the same interface as `CountVectorizer`. We will see that if we fit it on the same examples, we have the same vocabulary, and the vector for the text \"text\" is the same, but the vectors for the text \"another text\" will be different for `TfidfVectorizer` and `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "8e57e54a-bec9-4bdf-8dbd-2b5565facea3",
      "metadata": {
        "id": "8e57e54a-bec9-4bdf-8dbd-2b5565facea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad404b1-42db-4b0c-cf90-29f4653a0479"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'another': 0, 'is': 1, 'small': 2, 'text': 3, 'this': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer = tfidf_vectorizer.fit(toy_texts)\n",
        "tfidf_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6296b82e-d148-442a-be25-ac09f21083f5",
      "metadata": {
        "id": "6296b82e-d148-442a-be25-ac09f21083f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563c3c5f-3819-4810-8469-665ac1f21bd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "tfidf_vectorizer.transform([\"text\"]).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "48c96357-5a9c-466d-b2f7-ab3be5b63eff",
      "metadata": {
        "id": "48c96357-5a9c-466d-b2f7-ab3be5b63eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582e97b9-11de-4d39-f9d4-e95cd35f069b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Vector: [[1 0 0 1 0]]\n",
            "Count Vector: [[0.81480247 0.         0.         0.57973867 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Count Vector:\", count_vectorizer.transform([\"another text\"]).todense())\n",
        "print(\"Count Vector:\", tfidf_vectorizer.transform([\"another text\"]).todense())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66808424-86f9-4b03-aef1-edde90cbab7c",
      "metadata": {
        "id": "66808424-86f9-4b03-aef1-edde90cbab7c"
      },
      "source": [
        "This happens for two reasons:\n",
        "\n",
        "**First,** TfIDF is computed as two terms: term frequency (TF) or how many times we see the word in this text and inverse document frequency (IDF) or how many documents have this word in them.\n",
        "\n",
        "TF of a word is exactly what `CountVectorizer` do, just how many times we see a word in this particular text.\n",
        "\n",
        "IDF of a word is the number of documents in the training corpus that have this word (by training corpus we mean the texts we used to fit this vectorizer). More specifically, 1 divided by this number, hence, inverse.\n",
        "\n",
        "TF-IDF vectors usually work better than just Count Vectors in practice.\n",
        "\n",
        "\n",
        "**Second,** sklearn just uses normalization for the term frequency in `TfidfVectorizer` by default (i.e., it divides the vector by the number of words in the text), but doesn't do this for `CountVectorizer` for some reason. This normalization helps machine learning models to train more easily.\n",
        "\n",
        "\n",
        "There are multiple ways of combining these two values, the simplest being just multiplying them.\n",
        "\n",
        "`tfidf = TF * IDF`\n",
        "\n",
        "where\n",
        "\n",
        "`TF = word_count_in_text / total_words_in_text`\n",
        "\n",
        "`IDF = (document_count_with_this_word / total_documents) ** -1`\n",
        "\n",
        "> Sklearn uses a slightly different formula to better account for OOV and make the vectors less probable to cause computational errors idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1. You can look it up in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93ab0c8b-02f8-4d1e-8656-747ebd499175",
      "metadata": {
        "id": "93ab0c8b-02f8-4d1e-8656-747ebd499175"
      },
      "source": [
        "## Training a model\n",
        "\n",
        "Now let's fit a vectorizer on our training set of IMDB and train our first text classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "44d7f9b7-53bf-4aa1-b589-7c1df3342e46",
      "metadata": {
        "id": "44d7f9b7-53bf-4aa1-b589-7c1df3342e46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f093d58-5910-43ed-9925-0e0f69ee8cf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74849"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer = vectorizer.fit(train_set[\"text\"])\n",
        "len(vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "82da0821-dd30-49cf-aeda-8f1bd2e98ef8",
      "metadata": {
        "id": "82da0821-dd30-49cf-aeda-8f1bd2e98ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48641802-4561-4113-ea03-70ed87c2ddd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 74849)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "vectorized_texts = vectorizer.transform(train_set[\"text\"])\n",
        "vectorized_texts.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2454b5a-7671-44ec-b7f1-80e5b4d7835d",
      "metadata": {
        "id": "e2454b5a-7671-44ec-b7f1-80e5b4d7835d"
      },
      "source": [
        "This matrix has the shape `[num_examples, vector_size]`.\n",
        "We can see that the size of the text vector now is very big,\n",
        "because large collection of texts contains a lot of different words,\n",
        "meaning large vocabulary, meaning large vector size.\n",
        "\n",
        "Fortunately, this is not a problem for logistic regression, which is incredibly fast to train. (Ignore the warning, it means that LogisticRegression is not fully converged, but it is fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "eda43078-996f-4be0-8712-456a5bee77b4",
      "metadata": {
        "id": "eda43078-996f-4be0-8712-456a5bee77b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d991d839-e1e2-468f-cada-a192381770be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model = model.fit(vectorized_texts, train_set[\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2164a313-ef43-4e8b-9da8-0a6abf65da6b",
      "metadata": {
        "id": "2164a313-ef43-4e8b-9da8-0a6abf65da6b"
      },
      "source": [
        "Now we have a model that can do sentiment analysis for us! This is how you can use it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "52e57f03-b694-4459-abf4-2118d8c8ca87",
      "metadata": {
        "id": "52e57f03-b694-4459-abf4-2118d8c8ca87"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text, model, vectorizer):\n",
        "    text_vector = vectorizer.transform([text])\n",
        "    prediction = model.predict(text_vector)[0]\n",
        "    if prediction == 1:\n",
        "        return \"Positive\"\n",
        "    return \"Negative\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ef7f70c6-f154-4417-924c-a435a96a8e17",
      "metadata": {
        "id": "ef7f70c6-f154-4417-924c-a435a96a8e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0327c389-861e-4768-b177-fa7c0e4d40ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "predict_sentiment(\"this is an amazing movie!\", model, vectorizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78323d3c-811d-4a45-a010-022392da0279",
      "metadata": {
        "id": "78323d3c-811d-4a45-a010-022392da0279"
      },
      "source": [
        "# Coding task 4\n",
        "\n",
        "Play with the model you have just trained and try to find examples where it \n",
        "\n",
        "1. **correctly** predicts **positive** sentiment\n",
        "1. **correctly** predicts **negative** sentiment\n",
        "1. **incorrectly** predicts **positive** sentiment\n",
        "1. **incorrectly** predicts **negative** sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "a7add7ab-c5b0-4015-889c-63972cb66957",
      "metadata": {
        "id": "a7add7ab-c5b0-4015-889c-63972cb66957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01426279-c9de-4f2d-df69-51ce82d1943a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "Negative\n",
            "Negative\n",
            "Positive\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "print(predict_sentiment(\"In three years, everyone will be happy.\", model, vectorizer))\n",
        "print(predict_sentiment(\"He wasn't eating white rice.\", model, vectorizer))\n",
        "print(predict_sentiment(\"I don't have to commute to work.\", model, vectorizer))\n",
        "print(predict_sentiment(\"I woke up late so I have to go to the school as soon as possible.\", model, vectorizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba97dcb-2a31-4021-9639-4a82e787a864",
      "metadata": {
        "id": "3ba97dcb-2a31-4021-9639-4a82e787a864"
      },
      "source": [
        "# Inline question\n",
        "\n",
        "**Q6-9:** Try to explain model behavior for each case:\n",
        "\n",
        "1. There is including a clearly positive sentence \"everyone will be happy\", so this model's output was \"Positive\".\n",
        "1. Also, there is a clearly negative sentence \"He wasn't eating white rice.\", so this model's output was \"Negative\".\n",
        "1. However, in this case, this sentence has negative auxiliary verb \"don't\", so it can be seen as a negative sentence. But in terms of the overall flow, this means \"I work at home without having to commute\". So this is a positive sentence. But this model simply recognizes that it is negative without considering this flow.\n",
        "1. Also, this sentence doesn't have any negative auxiliary verb like \"don't\", so it can be seen as a positive sentence. Nevertheless, this model recognizes this is positive because this sentence has positive word \"possible\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797bbf28-0c58-4481-80f1-905daa7ecf32",
      "metadata": {
        "id": "797bbf28-0c58-4481-80f1-905daa7ecf32"
      },
      "source": [
        "## Evaluating the model\n",
        "\n",
        "We can see that model works. Kind of. How well exactly does it work? Let's compute accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "0ea37b7e-91d6-46cc-9374-1aa81855fac9",
      "metadata": {
        "id": "0ea37b7e-91d6-46cc-9374-1aa81855fac9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276b63f7-3c8c-4e41-a7cb-746a125c3a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is  0.86452\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "vectorized_texts_test = vectorizer.transform(test_set[\"text\"])\n",
        "test_set_predictions = model.predict(vectorized_texts_test)\n",
        "\n",
        "print(\"Test accuracy is \", accuracy_score(y_true=test_set[\"label\"], y_pred=test_set_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c91fbf6-15b6-4290-a2ef-db075e6597bc",
      "metadata": {
        "id": "1c91fbf6-15b6-4290-a2ef-db075e6597bc"
      },
      "source": [
        "Not too bad! 86% accuracy (on a balanced test set) using a really simple text representations that do not even account for the word order."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6387afd-9a79-472d-8293-1742ef436d73",
      "metadata": {
        "id": "a6387afd-9a79-472d-8293-1742ef436d73"
      },
      "source": [
        "# Inline question:\n",
        "\n",
        "**Q10:** Can we use a different vectorizer here?\n",
        "For example, can we fit a new `CountVectorizer` on the test set\n",
        "and use it instead of `vectorizer` we fitted on the train set?\n",
        "\n",
        "**A:** Yes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb8e5fc-a0e8-4f8c-9824-216aa32a2ece",
      "metadata": {
        "id": "0cb8e5fc-a0e8-4f8c-9824-216aa32a2ece"
      },
      "source": [
        "# Coding task 5\n",
        "### Optimizing pre-processing and hyperparameters\n",
        "\n",
        "Your next task is to improve the model and achieve more than 90% test accuracy. To simplify the experimentation, we provide you with a shorter code that builds a vectorizer, model, and evaluates everything in just a couple of lines of code.\n",
        "\n",
        "To improve the results you can play with different vectorizers, with different vectorizer parameters, and model regularization. We recommend comparing `CountVectorizer` with `TfidfVectorizer`, learning about ngrams, and controlling for the maximum number of features. For the model, we recommend tuning the regularization parameter. You can check all of these parameters out in the sklearn documentation.\n",
        "\n",
        "1. [CountVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "1. [TfidfVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "1. [LogisticRegression documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "\n",
        "> reading the documentation is an essential skill and it's better to start learning it as soon as possible\n",
        "\n",
        "\n",
        "Feel free to use other models from sklearn too (this is not necessary to achieve 90% accuracy).\n",
        "\n",
        "**NOTE:** It is ok to be stuck on this task for a bit, but if you can't seem to achieve more than 90% accuracy, feel free to contact our TA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "e79e54cd-83f5-431a-8575-3a6162894f2f",
      "metadata": {
        "id": "e79e54cd-83f5-431a-8575-3a6162894f2f"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (you can base it on the code provided)\n",
        "\n",
        "X = count_vectorizer.fit_transform(test_set[\"text\"])\n",
        "y = train_set[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "561a4132-563f-4f49-9ada-21dd68baa48a",
      "metadata": {
        "id": "561a4132-563f-4f49-9ada-21dd68baa48a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6418e6c4-fb7a-4997-b523-1032e2b7c3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9874"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "X_test = count_vectorizer.transform(test_set[\"text\"])\n",
        "y_test = test_set[\"label\"]\n",
        "model.score(X_test, y_test)  # computes accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ff01b5e-434f-400b-9189-d852c7c9875d",
      "metadata": {
        "id": "8ff01b5e-434f-400b-9189-d852c7c9875d"
      },
      "source": [
        "# Submitting your solution\n",
        "\n",
        "1. Restart the jupyter kernel and run the whole notebook (there's a single button to do this on the top panel). Make sure that the notebook executes completely without any issues. If you have bugs in the submitted notebook, this will affect your grade for this homework.\n",
        "\n",
        "2. Make sure you have answered all of the written questions (Q1-Q10) and have solved all of the coding tasks (5 in total).\n",
        "\n",
        "3. Pase your inline question answers to the [Google Form for this homework](https://forms.gle/Hhswn3W9WA1kUtvDA). For some of them, there are multiple correct answers (one of them is enough). 70% of correct answers account for the maximum inline question score, so there is no problem if one or three of them are answered incorrectly.\n",
        "\n",
        "4. Submit your notebook (executed top-to-bottom as in step 1) to blackboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "4d63cd2d-fe34-4edf-b3bb-ff1ef0a142df",
      "metadata": {
        "id": "4d63cd2d-fe34-4edf-b3bb-ff1ef0a142df"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "hw_1_linear_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d9a41ee0086a4d60a4eccdf02562e35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_469d2bbedf3d4f8cbfc9b0f1ed4237f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8989b49998d437f845da27a90a4f7f9",
              "IPY_MODEL_304fb578e5bb4a338457730410c1d1a6",
              "IPY_MODEL_e3c7aa497f234e37b1acf1e5b4b062f9"
            ]
          }
        },
        "469d2bbedf3d4f8cbfc9b0f1ed4237f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8989b49998d437f845da27a90a4f7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84b9c1f76f4144be846938c00fa0281a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8e53d2ec5254279b828ef1447a0f20a"
          }
        },
        "304fb578e5bb4a338457730410c1d1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df8b9ba71aaa4294b35454b7510c0ec7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_429e74a1955046b6be3fe063e170ce26"
          }
        },
        "e3c7aa497f234e37b1acf1e5b4b062f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39305c3c7b3b473e94eea5187dba2337",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 47.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cd4b8c3c125411392bb627be428f191"
          }
        },
        "84b9c1f76f4144be846938c00fa0281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8e53d2ec5254279b828ef1447a0f20a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df8b9ba71aaa4294b35454b7510c0ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "429e74a1955046b6be3fe063e170ce26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39305c3c7b3b473e94eea5187dba2337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cd4b8c3c125411392bb627be428f191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}